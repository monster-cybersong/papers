[
    {
        "title": "Towards Efficient Deployment of Hybrid SNNs on Neuromorphic and Edge AI\n  Hardware",
        "summary": "This paper explores the synergistic potential of neuromorphic and edge\ncomputing to create a versatile machine learning (ML) system tailored for\nprocessing data captured by dynamic vision sensors. We construct and train\nhybrid models, blending spiking neural networks (SNNs) and artificial neural\nnetworks (ANNs) using PyTorch and Lava frameworks. Our hybrid architecture\nintegrates an SNN for temporal feature extraction and an ANN for\nclassification. We delve into the challenges of deploying such hybrid\nstructures on hardware. Specifically, we deploy individual components on\nIntel's Neuromorphic Processor Loihi (for SNN) and Jetson Nano (for ANN). We\nalso propose an accumulator circuit to transfer data from the spiking to the\nnon-spiking domain. Furthermore, we conduct comprehensive performance analyses\nof hybrid SNN-ANN models on a heterogeneous system of neuromorphic and edge AI\nhardware, evaluating accuracy, latency, power, and energy consumption. Our\nfindings demonstrate that the hybrid spiking networks surpass the baseline ANN\nmodel across all metrics and outperform the baseline SNN model in accuracy and\nlatency.",
        "link": "http://arxiv.org/abs/2407.08704v1",
        "source": "arXiv",
        "date": "2024-07-11 17:40:39"
    },
    {
        "title": "Performance Evaluation of Neuromorphic Hardware for Onboard Satellite\n  Communication Applications",
        "summary": "Spiking neural networks (SNNs) implemented on neuromorphic processors (NPs)\ncan enhance the energy efficiency of deployments of artificial intelligence\n(AI) for specific workloads. As such, NP represents an interesting opportunity\nfor implementing AI tasks on board power-limited satellite communication\nspacecraft. In this article, we disseminate the findings of a recently\ncompleted study which targeted the comparison in terms of performance and\npower-consumption of different satellite communication use cases implemented on\nstandard AI accelerators and on NPs. In particular, the article describes three\nprominent use cases, namely payload resource optimization, onboard interference\ndetection and classification, and dynamic receive beamforming; and compare the\nperformance of conventional convolutional neural networks (CNNs) implemented on\nXilinx's VCK5000 Versal development card and SNNs on Intel's neuromorphic chip\nLoihi 2.",
        "link": "http://arxiv.org/abs/2401.06911v1",
        "source": "arXiv",
        "date": "2024-01-12 21:56:57"
    },
    {
        "title": "SPAIC: A sub-$\u03bc$W/Channel, 16-Channel General-Purpose Event-Based\n  Analog Front-End with Dual-Mode Encoders",
        "summary": "Low-power event-based analog front-ends (AFE) are a crucial component\nrequired to build efficient end-to-end neuromorphic processing systems for edge\ncomputing. Although several neuromorphic chips have been developed for\nimplementing spiking neural networks (SNNs) and solving a wide range of sensory\nprocessing tasks, there are only a few general-purpose analog front-end devices\nthat can be used to convert analog sensory signals into spikes and interfaced\nto neuromorphic processors. In this work, we present a novel, highly\nconfigurable analog front-end chip, denoted as SPAIC (signal-to-spike converter\nfor analog AI computation), that offers a general-purpose dual-mode analog\nsignal-to-spike encoding with delta modulation and pulse frequency modulation,\nwith tunable frequency bands. The ASIC is designed in a 180 nm process. It\nsupports and encodes a wide variety of signals spanning 4 orders of magnitude\nin frequency, and provides an event-based output that is compatible with\nexisting neuromorphic processors. We validated the ASIC for its functions and\npresent initial silicon measurement results characterizing the basic building\nblocks of the chip.",
        "link": "http://arxiv.org/abs/2309.03221v1",
        "source": "arXiv",
        "date": "2023-08-31 19:53:04"
    },
    {
        "title": "Gradient-descent hardware-aware training and deployment for mixed-signal\n  Neuromorphic processors",
        "summary": "Mixed-signal neuromorphic processors provide extremely low-power operation\nfor edge inference workloads, taking advantage of sparse asynchronous\ncomputation within Spiking Neural Networks (SNNs). However, deploying robust\napplications to these devices is complicated by limited controllability over\nanalog hardware parameters, as well as unintended parameter and dynamical\nvariations of analog circuits due to fabrication non-idealities. Here we\ndemonstrate a novel methodology for ofDine training and deployment of spiking\nneural networks (SNNs) to the mixed-signal neuromorphic processor DYNAP-SE2.\nThe methodology utilizes gradient-based training using a differentiable\nsimulation of the mixed-signal device, coupled with an unsupervised weight\nquantization method to optimize the network's parameters. Parameter noise\ninjection during training provides robustness to the effects of quantization\nand device mismatch, making the method a promising candidate for real-world\napplications under hardware constraints and non-idealities. This work extends\nRockpool, an open-source deep-learning library for SNNs, with support for\naccurate simulation of mixed-signal SNN dynamics. Our approach simplifies the\ndevelopment and deployment process for the neuromorphic community, making\nmixed-signal neuromorphic processors more accessible to researchers and\ndevelopers.",
        "link": "http://arxiv.org/abs/2303.12167v2",
        "source": "arXiv",
        "date": "2023-03-14 08:56:54"
    }
]